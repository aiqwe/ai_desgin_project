{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a025dcce-4c77-489c-b4ef-7dd76d6257dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:09:55.496268Z",
     "iopub.status.busy": "2024-06-10T05:09:55.495736Z",
     "iopub.status.idle": "2024-06-10T05:09:57.654641Z",
     "shell.execute_reply": "2024-06-10T05:09:57.654366Z",
     "shell.execute_reply.started": "2024-06-10T05:09:55.496236Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.chromadb import Chroma\n",
    "from src.inference import average_pool\n",
    "import json\n",
    "from multiprocessing import Pool, cpu_count, Lock\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6799b1fd-4e9a-43b3-b591-1c306d94aefb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T04:30:56.522711Z",
     "iopub.status.busy": "2024-06-10T04:30:56.522583Z",
     "iopub.status.idle": "2024-06-10T04:30:56.580199Z",
     "shell.execute_reply": "2024-06-10T04:30:56.579923Z",
     "shell.execute_reply.started": "2024-06-10T04:30:56.522701Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_name = \"poc\"\n",
    "\n",
    "chroma = Chroma(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c6a6a3-97c8-463b-a078-d7ac79a3f484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T04:31:51.619438Z",
     "iopub.status.busy": "2024-06-10T04:31:51.618676Z",
     "iopub.status.idle": "2024-06-10T04:31:51.719861Z",
     "shell.execute_reply": "2024-06-10T04:31:51.719077Z",
     "shell.execute_reply.started": "2024-06-10T04:31:51.619379Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chroma.create_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a516b5c-612e-463d-a611-e4734040ab6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T04:31:56.077947Z",
     "iopub.status.busy": "2024-06-10T04:31:56.077160Z",
     "iopub.status.idle": "2024-06-10T04:31:56.128780Z",
     "shell.execute_reply": "2024-06-10T04:31:56.127121Z",
     "shell.execute_reply.started": "2024-06-10T04:31:56.077886Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "poc = chroma.get_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbbd7f8d-a802-462b-81ef-5d27f7659468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:09:57.655430Z",
     "iopub.status.busy": "2024-06-10T05:09:57.655275Z",
     "iopub.status.idle": "2024-06-10T05:09:57.697454Z",
     "shell.execute_reply": "2024-06-10T05:09:57.697182Z",
     "shell.execute_reply.started": "2024-06-10T05:09:57.655420Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./src/data/health.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71a1a863-3064-4b17-b2a7-0ac09ff3c8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T04:42:56.677416Z",
     "iopub.status.busy": "2024-06-10T04:42:56.676796Z",
     "iopub.status.idle": "2024-06-10T04:42:56.699851Z",
     "shell.execute_reply": "2024-06-10T04:42:56.699449Z",
     "shell.execute_reply.started": "2024-06-10T04:42:56.677369Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = [\"###\" + ele['title'] + \"\\n\" + ele['text'] for ele in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c5b458-cd4f-442a-a622-1ff517182817",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:09:40.138647Z",
     "iopub.status.busy": "2024-06-10T05:09:40.138016Z",
     "iopub.status.idle": "2024-06-10T05:09:40.147683Z",
     "shell.execute_reply": "2024-06-10T05:09:40.146681Z",
     "shell.execute_reply.started": "2024-06-10T05:09:40.138610Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3604aa1-d365-49ac-8e75-68f1af3e6fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:10:07.401457Z",
     "iopub.status.busy": "2024-06-10T05:10:07.400822Z",
     "iopub.status.idle": "2024-06-10T05:10:07.408787Z",
     "shell.execute_reply": "2024-06-10T05:10:07.407004Z",
     "shell.execute_reply.started": "2024-06-10T05:10:07.401425Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d35a571-112e-4898-80c0-a171222a528f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:11:47.816604Z",
     "iopub.status.busy": "2024-06-10T05:11:47.815946Z",
     "iopub.status.idle": "2024-06-10T05:13:03.955333Z",
     "shell.execute_reply": "2024-06-10T05:13:03.953169Z",
     "shell.execute_reply.started": "2024-06-10T05:11:47.816572Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3744cdc061460f8ca8ce7200e6226c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/682 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19237767e87e495ab4a9ee68dfe5e8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/235M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f19000cb54489892c299ea9b840887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a64ed4b72804e4cb5249e2b1b9dc228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab49f1d80dfd4f76b6594df707bcbc53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/965 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:14,  1.24s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 30.97 GB, other allocations: 5.30 GB, max allowed: 36.27 GB). Tried to allocate 256 bytes on shared pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(cpu_count()\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m----> 7\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;44mlist\u001b[39;49m\u001b[44m(\u001b[49m\u001b[44mtqdm\u001b[49m\u001b[44m(\u001b[49m\u001b[44mp\u001b[49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mmap\u001b[49m\u001b[44m(\u001b[49m\u001b[44m_parallel_processing\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[44msample\u001b[49m\u001b[44m)\u001b[49m\u001b[44m)\u001b[49m\u001b[44m)\u001b[49m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m \u001b[44m    \u001b[49m\u001b[38;5;28;44;01mfor\u001b[39;49;00m\u001b[44m \u001b[49m\u001b[44mobj\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;129;44;01min\u001b[39;49;00m\u001b[44m \u001b[49m\u001b[44miterable\u001b[49m\u001b[44m:\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[44m        \u001b[49m\u001b[38;5;28;44;01myield\u001b[39;49;00m\u001b[44m \u001b[49m\u001b[44mobj\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[44m        \u001b[49m\u001b[38;5;66;44;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m \u001b[44m        \u001b[49m\u001b[38;5;66;44;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[44m_result_or_cancel\u001b[49m\u001b[44m(\u001b[49m\u001b[44mfs\u001b[49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mpop\u001b[49m\u001b[44m(\u001b[49m\u001b[44m)\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[44mfut\u001b[49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mresult\u001b[49m\u001b[44m(\u001b[49m\u001b[44mtimeout\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44m__get_result\u001b[49m\u001b[44m(\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mfn\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m, in \u001b[0;36m_parallel_processing\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parallel_processing\u001b[39m(data):\n\u001b[1;32m      2\u001b[0m     documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m###\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m     data\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[44maverage_pool\u001b[49m\u001b[44m(\u001b[49m\u001b[44mdocuments\u001b[49m\u001b[44m)\u001b[49m})\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Desktop/notebook/study/ai_design_project/src/inference.py:83\u001b[0m, in \u001b[0;36maverage_pool\u001b[0;34m(input_text, model, tokenizer, device)\u001b[0m\n\u001b[1;32m     73\u001b[0m     model, tokenizer \u001b[38;5;241m=\u001b[39m _call_default_model(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     75\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m     76\u001b[0m     input_text,\n\u001b[1;32m     77\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mmodel_max_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m )\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 83\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[44mmodel\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44minputs\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m     84\u001b[0m last_hidden \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmasked_fill(\u001b[38;5;241m~\u001b[39minputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mbool(), \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m     85\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m (last_hidden\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44m_call_impl\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[44mforward_call\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:988\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    979\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    981\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    982\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    983\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    986\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    987\u001b[0m )\n\u001b[0;32m--> 988\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mencoder\u001b[49m\u001b[44m(\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[44m    \u001b[49m\u001b[44membedding_output\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[44m    \u001b[49m\u001b[44mattention_mask\u001b[49m\u001b[38;5;241;44m=\u001b[39;49m\u001b[44mextended_attention_mask\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[44m    \u001b[49m\u001b[44mhead_mask\u001b[49m\u001b[38;5;241;44m=\u001b[39;49m\u001b[44mhead_mask\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[44m    \u001b[49m\u001b[44mencoder_hidden_states\u001b[49m\u001b[38;5;241;44m=\u001b[39;49m\u001b[44mencoder_hidden_states\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[44m    \u001b[49m\u001b[44mencoder_attention_mask\u001b[49m\u001b[38;5;241;44m=\u001b[39;49m\u001b[44mencoder_extended_attention_mask\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[44m    \u001b[49m\u001b[44mpast_key_values\u001b[49m\u001b[38;5;241;44m=\u001b[39;49m\u001b[44mpast_key_values\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[44m    \u001b[49m\u001b[44muse_cache\u001b[49m\u001b[38;5;241;44m=\u001b[39;49m\u001b[44muse_cache\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[44m    \u001b[49m\u001b[44moutput_attentions\u001b[49m\u001b[38;5;241;44m=\u001b[39;49m\u001b[44moutput_attentions\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[44m    \u001b[49m\u001b[44moutput_hidden_states\u001b[49m\u001b[38;5;241;44m=\u001b[39;49m\u001b[44moutput_hidden_states\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[44m    \u001b[49m\u001b[44mreturn_dict\u001b[49m\u001b[38;5;241;44m=\u001b[39;49m\u001b[44mreturn_dict\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[44m\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m   1000\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1001\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44m_call_impl\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[44mforward_call\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:582\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    571\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    572\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    573\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         output_attentions,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 582\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[44mlayer_module\u001b[49m\u001b[44m(\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[44m        \u001b[49m\u001b[44mhidden_states\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[44m        \u001b[49m\u001b[44mattention_mask\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[44m        \u001b[49m\u001b[44mlayer_head_mask\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[44m        \u001b[49m\u001b[44mencoder_hidden_states\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[44m        \u001b[49m\u001b[44mencoder_attention_mask\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[44m        \u001b[49m\u001b[44mpast_key_value\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[44m        \u001b[49m\u001b[44moutput_attentions\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[44m    \u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m    592\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44m_call_impl\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[44mforward_call\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    462\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mattention\u001b[49m\u001b[44m(\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[44m        \u001b[49m\u001b[44mhidden_states\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[44m        \u001b[49m\u001b[44mattention_mask\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[44m        \u001b[49m\u001b[44mhead_mask\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[44m        \u001b[49m\u001b[44moutput_attentions\u001b[49m\u001b[38;5;241;44m=\u001b[39;49m\u001b[44moutput_attentions\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[44m        \u001b[49m\u001b[44mpast_key_value\u001b[49m\u001b[38;5;241;44m=\u001b[39;49m\u001b[44mself_attn_past_key_value\u001b[49m\u001b[44m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[44m    \u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44m_call_impl\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[44mforward_call\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:411\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    394\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    401\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    402\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    403\u001b[0m         hidden_states,\n\u001b[1;32m    404\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    409\u001b[0m         output_attentions,\n\u001b[1;32m    410\u001b[0m     )\n\u001b[0;32m--> 411\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44moutput\u001b[49m\u001b[44m(\u001b[49m\u001b[44mself_outputs\u001b[49m\u001b[44m[\u001b[49m\u001b[38;5;241;44m0\u001b[39;49m\u001b[44m]\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[44mhidden_states\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44m_call_impl\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[44mforward_call\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:363\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    361\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    362\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 363\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mLayerNorm\u001b[49m\u001b[44m(\u001b[49m\u001b[44mhidden_states\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m+\u001b[39;49m\u001b[44m \u001b[49m\u001b[44minput_tensor\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44m_call_impl\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[44mforward_call\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44margs\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[38;5;241;44m*\u001b[39;49m\u001b[44mkwargs\u001b[49m\u001b[44m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/modules/normalization.py:196\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[44mF\u001b[49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mlayer_norm\u001b[49m\u001b[44m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[44m        \u001b[49m\u001b[38;5;28;44minput\u001b[39;49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mnormalized_shape\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mweight\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mbias\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[38;5;28;44mself\u001b[39;49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44meps\u001b[49m\u001b[44m)\u001b[49m\n",
      "File \u001b[0;32m~/.base/lib/python3.11/site-packages/torch/nn/functional.py:2543\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2541\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2542\u001b[0m     )\n\u001b[0;32m-> 2543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[44mtorch\u001b[49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mlayer_norm\u001b[49m\u001b[44m(\u001b[49m\u001b[38;5;28;44minput\u001b[39;49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[44mnormalized_shape\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[44mweight\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[44mbias\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[44meps\u001b[49m\u001b[44m,\u001b[49m\u001b[44m \u001b[49m\u001b[44mtorch\u001b[49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mbackends\u001b[49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44mcudnn\u001b[49m\u001b[38;5;241;44m.\u001b[39;49m\u001b[44menabled\u001b[49m\u001b[44m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 30.97 GB, other allocations: 5.30 GB, max allowed: 36.27 GB). Tried to allocate 256 bytes on shared pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "def _parallel_processing(data):\n",
    "    documents = \"###\" + data['title'] + \"\\n\" + data['text']\n",
    "    data.update({\"documents\": average_pool(documents)})\n",
    "    return data\n",
    "\n",
    "with ThreadPoolExecutor(cpu_count()-2) as p:\n",
    "    embeddings = list(tqdm(p.map(_parallel_processing, sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b7fd3-7f53-4b5c-9670-9a4e3778dd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b261df-c70b-4cd0-8f3b-28633029973b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09f0e2-32eb-4000-b539-6b035d27371b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd40fde3-0bf6-4c6c-899c-28f56c7a9152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a90edcc7-e1ff-4781-bb5c-6dde282a7cdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T11:23:40.116192Z",
     "iopub.status.busy": "2024-06-05T11:23:40.115697Z",
     "iopub.status.idle": "2024-06-05T11:23:40.145368Z",
     "shell.execute_reply": "2024-06-05T11:23:40.144865Z",
     "shell.execute_reply.started": "2024-06-05T11:23:40.116165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c38ab6bb-3000-4e36-8d76-9f67cd305a83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T11:23:41.166497Z",
     "iopub.status.busy": "2024-06-05T11:23:41.165394Z",
     "iopub.status.idle": "2024-06-05T11:23:41.183991Z",
     "shell.execute_reply": "2024-06-05T11:23:41.183285Z",
     "shell.execute_reply.started": "2024-06-05T11:23:41.166352Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3feca13-9eb7-4aab-a73d-1aac1eca0b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T11:23:41.499003Z",
     "iopub.status.busy": "2024-06-05T11:23:41.498767Z",
     "iopub.status.idle": "2024-06-05T11:23:56.663289Z",
     "shell.execute_reply": "2024-06-05T11:23:56.662893Z",
     "shell.execute_reply.started": "2024-06-05T11:23:41.498983Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9v/m6xmlrwd42q8n8bkflvbst0h0000gn/T/ipykernel_10421/303394245.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample['embedding'] = (sample['title'] + \":\" + sample['text']).apply(lambda x: average_pool(x).tolist()[0])\n"
     ]
    }
   ],
   "source": [
    "sample['embedding'] = (sample['title'] + \":\" + sample['text']).apply(lambda x: average_pool(x).tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "144c0087-ec60-44f0-b6df-859f21a5d43c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T11:19:51.435450Z",
     "iopub.status.busy": "2024-06-05T11:19:51.435365Z",
     "iopub.status.idle": "2024-06-05T11:19:51.438166Z",
     "shell.execute_reply": "2024-06-05T11:19:51.437645Z",
     "shell.execute_reply.started": "2024-06-05T11:19:51.435442Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9v/m6xmlrwd42q8n8bkflvbst0h0000gn/T/ipykernel_10421/372242415.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample['text'] = (sample['title'] + \":\" + sample['text'])\n"
     ]
    }
   ],
   "source": [
    "sample['text'] = (sample['title'] + \":\" + sample['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "831f964a-fecb-45cf-a49f-29c4af90dee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T11:25:56.954108Z",
     "iopub.status.busy": "2024-06-05T11:25:56.953909Z",
     "iopub.status.idle": "2024-06-05T11:25:56.957676Z",
     "shell.execute_reply": "2024-06-05T11:25:56.957212Z",
     "shell.execute_reply.started": "2024-06-05T11:25:56.954092Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://terms.naver.com/entry.naver?docId=926652&cid=51007&categoryId=51007'},\n",
       " {'url': 'https://terms.naver.com/entry.naver?docId=926581&cid=51007&categoryId=51007'},\n",
       " {'url': 'https://terms.naver.com/entry.naver?docId=6226078&cid=51007&categoryId=51007'},\n",
       " {'url': 'https://terms.naver.com/entry.naver?docId=926835&cid=51007&categoryId=51007'},\n",
       " {'url': 'https://terms.naver.com/entry.naver?docId=926659&cid=51007&categoryId=51007'},\n",
       " {'url': 'https://terms.naver.com/entry.naver?docId=926702&cid=51007&categoryId=51007'},\n",
       " {'url': 'https://terms.naver.com/entry.naver?docId=5646470&cid=60406&categoryId=60406'},\n",
       " {'url': 'https://terms.naver.com/entry.naver?docId=926919&cid=51007&categoryId=51007'},\n",
       " {'url': 'https://terms.naver.com/entry.naver?docId=926829&cid=51007&categoryId=51007'},\n",
       " {'url': 'https://terms.naver.com/entry.naver?docId=926619&cid=51007&categoryId=51007'}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{\"url\": v} for v in sample[:10]['url'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "956189d3-6614-42a2-b8e2-0bac8a955e6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T11:26:07.367206Z",
     "iopub.status.busy": "2024-06-05T11:26:07.365599Z",
     "iopub.status.idle": "2024-06-05T11:26:07.675471Z",
     "shell.execute_reply": "2024-06-05T11:26:07.675173Z",
     "shell.execute_reply.started": "2024-06-05T11:26:07.367155Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.upsert(documents = sample[:10]['text'].tolist(),\n",
    "            ids = sample[:10]['title'].tolist(),\n",
    "            metadatas = [{\"url\": v} for v in sample[:10]['url'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6dcb2c76-9728-45b1-bb1b-fd51ac40883a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T11:26:45.557693Z",
     "iopub.status.busy": "2024-06-05T11:26:45.557246Z",
     "iopub.status.idle": "2024-06-05T11:26:45.619871Z",
     "shell.execute_reply": "2024-06-05T11:26:45.619452Z",
     "shell.execute_reply.started": "2024-06-05T11:26:45.557663Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = test.query(query_texts=\"백일해\", n_results=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "187f5f6c-3592-4b27-b7ef-785eb437deae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T11:26:46.840140Z",
     "iopub.status.busy": "2024-06-05T11:26:46.838942Z",
     "iopub.status.idle": "2024-06-05T11:26:46.859129Z",
     "shell.execute_reply": "2024-06-05T11:26:46.858626Z",
     "shell.execute_reply.started": "2024-06-05T11:26:46.840076Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://terms.naver.com/entry.naver?docId=6226078&cid=51007&categoryId=51007'}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['metadatas'][0][0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f298564-576e-4a67-865e-72f6adbb2498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef802305-7540-431e-b78e-e9d84720b5cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T11:28:51.033928Z",
     "iopub.status.busy": "2024-06-04T11:28:51.033746Z",
     "iopub.status.idle": "2024-06-04T11:28:51.088835Z",
     "shell.execute_reply": "2024-06-04T11:28:51.088544Z",
     "shell.execute_reply.started": "2024-06-04T11:28:51.033910Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=test)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8cab7bc9-72d4-42bf-924d-a24b2f3c4da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T11:29:00.730498Z",
     "iopub.status.busy": "2024-06-04T11:29:00.730254Z",
     "iopub.status.idle": "2024-06-04T11:29:00.970609Z",
     "shell.execute_reply": "2024-06-04T11:29:00.970318Z",
     "shell.execute_reply.started": "2024-06-04T11:29:00.730478Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.delete_collection(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d8704-96c6-4e9d-a2a4-57bc816fbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    " collection = client.create_collection(\n",
    "        name=\"collection_name\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"} # l2 is the default\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cee311b-36d8-4fe1-8840-6acd4c52c877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T09:38:35.491493Z",
     "iopub.status.busy": "2024-06-05T09:38:35.490480Z",
     "iopub.status.idle": "2024-06-05T09:38:35.502182Z",
     "shell.execute_reply": "2024-06-05T09:38:35.501497Z",
     "shell.execute_reply.started": "2024-06-05T09:38:35.491447Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = \"first : {hi}, second: {hello}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03d423c6-662b-467d-97e1-498cab20bb66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T09:38:53.164095Z",
     "iopub.status.busy": "2024-06-05T09:38:53.163131Z",
     "iopub.status.idle": "2024-06-05T09:38:53.180494Z",
     "shell.execute_reply": "2024-06-05T09:38:53.179634Z",
     "shell.execute_reply.started": "2024-06-05T09:38:53.164038Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first : hihihi, second: hellohello'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.format(hi=\"hihihi\", hello=\"hellohello\", url=\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9883c3eb-c3ab-467f-90c0-5a4beb60e874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T09:46:06.726197Z",
     "iopub.status.busy": "2024-06-05T09:46:06.725621Z",
     "iopub.status.idle": "2024-06-05T09:46:06.743493Z",
     "shell.execute_reply": "2024-06-05T09:46:06.742860Z",
     "shell.execute_reply.started": "2024-06-05T09:46:06.726166Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(config):\n",
    "    test = \"first : {hi}, second: {hello}\"\n",
    "    test = test.format(**config)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4736464-4d1c-4559-81b6-29e7b05343f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T09:46:09.225402Z",
     "iopub.status.busy": "2024-06-05T09:46:09.224964Z",
     "iopub.status.idle": "2024-06-05T09:46:09.237732Z",
     "shell.execute_reply": "2024-06-05T09:46:09.237008Z",
     "shell.execute_reply.started": "2024-06-05T09:46:09.225374Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first : hihihihi, second: hellohello'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test({'hi': 'hihihihi', 'hello': 'hellohello'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac45b1f6-fbfd-4953-885b-bc247ad626f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T10:45:35.327948Z",
     "iopub.status.busy": "2024-06-05T10:45:35.327745Z",
     "iopub.status.idle": "2024-06-05T10:45:35.330314Z",
     "shell.execute_reply": "2024-06-05T10:45:35.329775Z",
     "shell.execute_reply.started": "2024-06-05T10:45:35.327934Z"
    }
   },
   "outputs": [],
   "source": [
    "test = [[1], [2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4bed2594-1e42-4420-b8a4-59972dac46d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T10:45:47.785599Z",
     "iopub.status.busy": "2024-06-05T10:45:47.784420Z",
     "iopub.status.idle": "2024-06-05T10:45:47.797575Z",
     "shell.execute_reply": "2024-06-05T10:45:47.795511Z",
     "shell.execute_reply.started": "2024-06-05T10:45:47.785549Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t[0]+1 for t in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca4a84e5-f0bb-48f1-aa3f-e6c451e4b95a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T10:49:26.073474Z",
     "iopub.status.busy": "2024-06-05T10:49:26.073297Z",
     "iopub.status.idle": "2024-06-05T10:49:26.077172Z",
     "shell.execute_reply": "2024-06-05T10:49:26.075326Z",
     "shell.execute_reply.started": "2024-06-05T10:49:26.073458Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "r = json.dumps([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b50d6539-2639-4476-a23c-2425a1e41af7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T10:49:32.619917Z",
     "iopub.status.busy": "2024-06-05T10:49:32.619440Z",
     "iopub.status.idle": "2024-06-05T10:49:32.633932Z",
     "shell.execute_reply": "2024-06-05T10:49:32.632858Z",
     "shell.execute_reply.started": "2024-06-05T10:49:32.619892Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(r, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000165a-4da4-4d1b-a6bd-89666dec65a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": ".base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
